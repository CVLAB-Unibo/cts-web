<section class="hero  has-text-centered" id="paper">
    <div class="hero-body">
        <div class="container">
          <h2><a href=“https://github.com/CVLAB-Unibo/CtS”>Official Code</a></h2>
          <h2 align="centered" class="title">PAPER</h2>
            <div class="columns">
                <div class="column is-one-fifth-desktop is-one-fifth-tablet is-one-fifth-fullhd">
                  <br>
                  <br>
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/10214589">
                  <img style="width:90%" src="assets/images/paper_image.jpg" >
                  </a>
                </div>
                <div class="column has-text-left-desktop has-text-left-tablet has-text-left-fullhd has-text-left-widescreen">

                    <br>
                    <div class="container columns is-centered">
                        <div>
                          <B><a href="https://ieeexplore.ieee.org/document/10214589"><font size = "+2">Boosting Multi-Modal Unsupervised Domain Adaptation for LiDAR Semantic Segmentation by Self-Supervised Depth Completion</font></a><br></B>
                          <B><i> Adriano Cardace, Andrea Conti, Pierluigi Zama Ramirez, Riccardo Spezialetti, Samuele Salti, Luigi Di Stefano</B></i>
                          <br>
                          <br>
                          <p>
                            LiDAR semantic segmentation is receiving increased attention due to its deployment in autonomous driving applications. As LiDARs come often with other sensors such as RGB cameras, multi-modal approaches for this task have been developed, which however suffer from the domain shift problem as other deep learning approaches. To address this, we propose a novel Unsupervised Domain Adaptation (UDA) technique for multi-modal LiDAR segmentation. Unlike previous works in this field, we leverage depth completion as an auxiliary task to align features extracted from 2D images across domains, and as a powerful data augmentation for LiDARs.
                            We validate our method on three popular multi-modal UDA benchmarks and we achieve better performances than other competitors.
                          </div>
                        <div>

                        </div>
                    </div>
                </div>
            </div>
            <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                CITATION
                </h3>
                <div class="has-text-left-desktop has-text-left-tablet has-text-left-fullhd has-text-left-widescreen form-group col-md-18 col-md-offset-0">
<pre>
    
  @article{cardace2023cts,
    title={Boosting Multi-Modal Unsupervised Domain Adaptation for LiDAR Semantic Segmentation by Self-Supervised Depth Completion},
    author={Cardace, Adriano and Conti, Andrea and Zama Ramirez, Pierluigi and Spezialetti, Riccardo and Salti, Samuele and Di Stefano, Luigi},
    journal={IEEE Access},
    year={2023},
    publisher={IEEE}
  }

</pre>
</section>
